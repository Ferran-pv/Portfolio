{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82c7e9b7-65f9-4ae2-9fb4-9a05bb0fb048",
   "metadata": {},
   "source": [
    "# Start project\n",
    "\n",
    "I tested my code within Ubuntu. It should work fine within MAC or linux distributions. \\\n",
    "I assume Jupyter Lab is installed (pip install jupyterlab).\n",
    "\n",
    "## Python virtual environment\n",
    "\n",
    "We start the project executing in the terminal: **./0Create_venv.sh CreateVenv**\n",
    "- Creates a Python venv, activates and opens JupyterLab, which is using 'venv' kernel.\n",
    "- If you already did it and only want to open Jupyter lab with the 'venv' kernel: ./0Create_venv.sh OpenJlab\n",
    "- To upddate packages installed: ! pip3 install -r 0requirements.txt\n",
    "\n",
    "\n",
    "## Directory structure\n",
    "\n",
    "You can do a quick overview with the command in next chunk.\n",
    "\n",
    "\n",
    "### Notebooks\n",
    "\n",
    "[test](notebooks/test.ipynb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5d8abc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os.path\n",
    "os.path.isfile(\"data/air_pollution.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "115d78e9-cb14-4372-a41f-c6a0579c4214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ ML_TS/\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€ğŸ“ .virtual_documents/\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€ğŸ“ data/\n",
      "â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€ğŸ“„ air_pollution.csv\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€ğŸ“ modules/\n",
      "â”‚         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€ğŸ“ architectures/\n",
      "â”‚         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€ğŸ“ models/\n",
      "â”‚         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€ğŸ“„ 0Create_venv.sh\n",
      "â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€ğŸ“„ 0LoadData_Libraries.py\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€ğŸ“ notebooks/\n",
      "â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€ğŸ“„ test.ipynb\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€ğŸ“„ 0requirements.txt\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€ğŸ“„ README.ipynb\n"
     ]
    }
   ],
   "source": [
    "import seedir \n",
    "seedir.seedir(style='emoji', depthlimit=5, exclude_folders=['.venv','.ipynb_checkpoints','.git'],indent=10,first='folders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3d57ab-cb7f-4dab-8b71-0281a63db257",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "196643e4-4419-46c9-a788-534b5a9cf0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries loaded!\n",
      "air_pollution.csv loaded! \n",
      "\n",
      "\n",
      "            pollution_today     dew  ...  rain  pollution_yesterday\n",
      "date                                 ...                           \n",
      "2010-01-02       145.958333  -8.500  ...   0.0            10.041667\n",
      "2010-01-03        78.833333 -10.125  ...   0.0           145.958333\n",
      "\n",
      "[2 rows x 8 columns]\n",
      "1461 days of training data \n",
      " 364 days of testing data \n"
     ]
    }
   ],
   "source": [
    "%run modules/0LoadData_Libraries.py \n",
    "\n",
    "split_date = '2014-01-01'\n",
    "df_training = air_pollution.loc[air_pollution.index <= split_date]\n",
    "df_test = air_pollution.loc[air_pollution.index > split_date]\n",
    "print(f\"{len(df_training)} days of training data \\n {len(df_test)} days of testing data \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db39dab9-b89b-449c-adde-2f9cbce444bf",
   "metadata": {},
   "source": [
    "The auro_arima function works by conducting differencing tests (i.e., Kwiatkowskiâ€“Phillipsâ€“Schmidtâ€“Shin, Augmented Dickey-Fuller or Phillipsâ€“Perron) to determine the order of differencing, d, and then fitting models within ranges of defined start_p, max_p, start_q, max_q ranges. If the seasonal optional is enabled, auto_arima also seeks to identify the optimal P and Q hyper- parameters after conducting the Canova-Hansen to determine the optimal order of seasonal differencing, D.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b93aa24-844d-4181-855c-4e3b9e38e948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Test Statistic : -20.670430837487448\n",
      "p-value : 0.0\n",
      "#Lags Used : 1\n",
      "Number of Observations Used : 1459\n",
      "P value is less than 0.05 that means we can reject the null hypothesis(Ho). Therefore we can conclude that data has no unit root and is stationary\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.arima.model  import ARIMA\n",
    "\n",
    "#### 1 \n",
    "# Testing For Stationarity of Data using Statsmodels adfuller\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "test_result=adfuller(df_training[\"pollution_today\"])\n",
    "test_result\n",
    "#Ho: It is non stationary\n",
    "#H1: It is stationary\n",
    "# https://www.nbshare.io/notebook/136553745/Time-Series-Analysis-Using-ARIMA-From-StatsModels/\n",
    "def adfuller_test(sales):\n",
    "    result=adfuller(sales)\n",
    "    labels = ['ADF Test Statistic','p-value','#Lags Used','Number of Observations Used']\n",
    "    for value,label in zip(result,labels):\n",
    "        print(label+' : '+str(value) )\n",
    "    if result[1] <= 0.05:\n",
    "        print(\"P value is less than 0.05 that means we can reject the null hypothesis(Ho). Therefore we can conclude that data has no unit root and is stationary\")\n",
    "    else:\n",
    "        print(\"Weak evidence against null hypothesis that means time series has a unit root which indicates that it is non-stationary \")\n",
    "adfuller_test(df_training[\"pollution_today\"])\n",
    "# df['Sales First Difference'] = df['Sales'] - df['Sales'].shift(1)\n",
    "\n",
    "\n",
    "# AUTO_ARMA\n",
    "# select arma order: https://www.statsmodels.org/devel/generated/statsmodels.tsa.stattools.arma_order_select_ic.html#statsmodels.tsa.stattools.arma_order_select_ic\n",
    "\n",
    "#arima_model = ARIMA(df_training[\"pollution_today\"].values)\n",
    "#print(arima_model)model = arima_model.fit()\n",
    "#print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1140c8e-ce13-45c5-a626-06733602f8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/secretstorage/dhcrypto.py:15: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/usr/lib/python3/dist-packages/secretstorage/util.py:19: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting statsforecast\n",
      "  Downloading statsforecast-1.0.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numpy>=1.21.6\n",
      "  Using cached numpy-1.23.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "Collecting pandas>=1.3.5\n",
      "  Downloading pandas-1.4.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting statsmodels>=0.13.2\n",
      "  Using cached statsmodels-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
      "Collecting scipy>=1.7.3\n",
      "  Downloading scipy-1.9.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0mm[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numba>=0.55.0 in /home/ferran/.local/lib/python3.8/site-packages (from statsforecast) (0.55.1)\n",
      "Collecting numpy>=1.21.6\n",
      "  Downloading numpy-1.21.6-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from numba>=0.55.0->statsforecast) (45.2.0)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /home/ferran/.local/lib/python3.8/site-packages (from numba>=0.55.0->statsforecast) (0.38.0)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2022.2.1-py2.py3-none-any.whl (500 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ferran/.local/lib/python3.8/site-packages (from pandas>=1.3.5->statsforecast) (2.8.2)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /home/ferran/.local/lib/python3.8/site-packages (from statsmodels>=0.13.2->statsforecast) (0.5.2)\n",
      "Collecting packaging>=21.3\n",
      "  Using cached packaging-21.3-py3-none-any.whl (40 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ferran/.local/lib/python3.8/site-packages (from packaging>=21.3->statsmodels>=0.13.2->statsforecast) (2.4.7)\n",
      "Requirement already satisfied: six in /home/ferran/.local/lib/python3.8/site-packages (from patsy>=0.5.2->statsmodels>=0.13.2->statsforecast) (1.15.0)\n",
      "Installing collected packages: pytz, packaging, numpy, scipy, pandas, statsmodels, statsforecast\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 20.4\n",
      "    Uninstalling packaging-20.4:\n",
      "      Successfully uninstalled packaging-20.4\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.6.0\n",
      "    Uninstalling scipy-1.6.0:\n",
      "      Successfully uninstalled scipy-1.6.0\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.2.0\n",
      "    Uninstalling pandas-1.2.0:\n",
      "      Successfully uninstalled pandas-1.2.0\n",
      "  Attempting uninstall: statsmodels\n",
      "    Found existing installation: statsmodels 0.13.1\n",
      "    Uninstalling statsmodels-0.13.1:\n",
      "      Successfully uninstalled statsmodels-0.13.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.4.0 requires numpy~=1.19.2, but you have numpy 1.21.6 which is incompatible.\n",
      "kedro-viz 5.0.0 requires ipython<8.0,>=7.0.0, but you have ipython 8.4.0 which is incompatible.\n",
      "imbalanced-learn 0.9.0 requires scikit-learn>=1.0.1, but you have scikit-learn 0.24.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.21.6 packaging-21.3 pandas-1.4.3 pytz-2022.2.1 scipy-1.9.1 statsforecast-1.0.0 statsmodels-0.13.2\n"
     ]
    }
   ],
   "source": [
    "#!pip install statsmodels\n",
    "!pip install statsforecast"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
